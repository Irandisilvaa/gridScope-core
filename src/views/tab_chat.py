import streamlit as st
import requests
import time

CHAT_API_URL = "http://127.0.0.1:8002"


def consultar_chat(mensagem: str, historico: list) -> dict:
    try:
        payload = {
            "mensagem": mensagem,
            "historico": historico
        }
        
        response = requests.post(
            f"{CHAT_API_URL}/chat/message",
            json=payload,
            timeout=120
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            return {
                "resposta": f"âŒ Erro na API: {response.status_code}",
                "historico_atualizado": historico
            }
            
    except requests.exceptions.ConnectionError:
        return {
            "resposta": "âŒ NÃ£o foi possÃ­vel conectar Ã  API de chat. Certifique-se de que o serviÃ§o estÃ¡ rodando (python src/ai/chat_service.py)",
            "historico_atualizado": historico
        }
    except Exception as e:
        return {
            "resposta": f"âŒ Erro: {str(e)}",
            "historico_atualizado": historico
        }


def render_view():
    st.title("ğŸ’¬ Chat com IA - Consulta de Dados")
    st.markdown("FaÃ§a perguntas sobre os dados do sistema elÃ©trico")
    
    if "chat_historico" not in st.session_state:
        st.session_state.chat_historico = []
    
    if "chat_mensagens" not in st.session_state:
        st.session_state.chat_mensagens = []
    
    st.markdown("### ğŸ’¡ Perguntas Sugeridas")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š Quantos consumidores temos?", use_container_width=True):
            st.session_state.pergunta_sugerida = "Quantos consumidores temos no total?"
    
    with col2:
        if st.button("âš¡ Qual subestaÃ§Ã£o gera mais energia?", use_container_width=True):
            st.session_state.pergunta_sugerida = "Qual subestaÃ§Ã£o tem maior potÃªncia de geraÃ§Ã£o distribuÃ­da?"
    
    with col3:
        if st.button("ğŸš¨ Quais subestaÃ§Ãµes estÃ£o em risco?", use_container_width=True):
            st.session_state.pergunta_sugerida = "Quais subestaÃ§Ãµes estÃ£o em risco crÃ­tico de geraÃ§Ã£o distribuÃ­da?"
    
    col4, col5, col6 = st.columns(3)
    
    with col4:
        if st.button("ğŸ  DistribuiÃ§Ã£o por classe", use_container_width=True):
            st.session_state.pergunta_sugerida = "Como estÃ¡ a distribuiÃ§Ã£o de consumo por classe (residencial, comercial, industrial)?"
    
    with col5:
        if st.button("ğŸ“ˆ Top 5 consumidores", use_container_width=True):
            st.session_state.pergunta_sugerida = "Me mostre as 5 subestaÃ§Ãµes que mais consomem energia"
    
    with col6:
        if st.button("ğŸ” EstatÃ­sticas gerais", use_container_width=True):
            st.session_state.pergunta_sugerida = "Me dÃª um resumo das estatÃ­sticas gerais do sistema"
    
    st.markdown("---")
    
    st.markdown("### ğŸ’¬ Conversa")
    
    chat_container = st.container()
    
    with chat_container:
        for msg in st.session_state.chat_mensagens:
            if msg["role"] == "user":
                with st.chat_message("user"):
                    st.markdown(msg["content"])
            else:
                with st.chat_message("assistant"):
                    st.markdown(msg["content"])
    
    pergunta_input = st.chat_input("Digite sua pergunta sobre os dados...")
    
    if "pergunta_sugerida" in st.session_state:
        pergunta_input = st.session_state.pergunta_sugerida
        del st.session_state.pergunta_sugerida
    
    if pergunta_input:
        st.session_state.chat_mensagens.append({
            "role": "user",
            "content": pergunta_input
        })
        
        with chat_container:
            with st.chat_message("user"):
                st.markdown(pergunta_input)
        
        with st.spinner("Consultando dados..."):
            resultado = consultar_chat(pergunta_input, st.session_state.chat_historico)
        
        resposta_ia = resultado.get("resposta", "Erro ao processar resposta")
        
        # DEBUG: Verificar resposta
        print(f"ğŸ” DEBUG - Resposta recebida: {resposta_ia[:200] if resposta_ia else 'VAZIA'}")
        
        if not resposta_ia or resposta_ia.strip() == "":
            resposta_ia = "âš ï¸ Recebi uma resposta vazia da API. Tente novamente."
        
        st.session_state.chat_mensagens.append({
            "role": "assistant",
            "content": resposta_ia
        })
        
        st.session_state.chat_historico = resultado.get("historico_atualizado", [])
        
        st.rerun()
    
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ Limpar Conversa"):
        st.session_state.chat_historico = []
        st.session_state.chat_mensagens = []
        st.rerun()
    
    st.markdown("---")
    st.caption("ğŸ’¡ Dica: FaÃ§a perguntas especÃ­ficas sobre subestaÃ§Ãµes, consumo, geraÃ§Ã£o distribuÃ­da ou estatÃ­sticas do sistema")
    
    try:
        health = requests.get(f"{CHAT_API_URL}/health", timeout=2)
        if health.status_code == 200:
            info = health.json()
            if info.get("api_configured"):
                st.success(f"âœ… Chat IA Online - Modelo: {info.get('model')}")
            else:
                st.warning("âš ï¸ API Key do Gemini nÃ£o configurada! Adicione GEMINI_API_KEY no arquivo .env")
        else:
            st.error("âŒ API de Chat nÃ£o estÃ¡ respondendo corretamente")
    except:
        st.error("âŒ API de Chat offline. Inicie o serviÃ§o com: `python src/ai/chat_service.py`")


if __name__ == "__main__":
    render_view()
