import os
import sys
import json
import traceback
from typing import List, Dict, Any

from google import genai
from google.genai import types
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import CHAT_API_KEY, CHAT_MODEL
from ai.chat_queries import FUNCOES_DISPONIVEIS

client = genai.Client(api_key=CHAT_API_KEY)

app = FastAPI(title="GridScope Chat IA", version="1.0")

CONTEXTO_SISTEMA = """
Voc√™ √© um assistente de dados do GridScope, sistema de an√°lise de redes el√©tricas.

SUA FUN√á√ÉO:
- Responder perguntas sobre os DADOS do sistema el√©trico
- Consultar o banco de dados PostgreSQL quando necess√°rio
- Apresentar estat√≠sticas, rankings e an√°lises dos dados

üö® REGRAS CR√çTICAS - NUNCA VIOLAR:
1. **NUNCA invente dados, nomes de subesta√ß√µes ou n√∫meros**
2. **Use APENAS os dados retornados pelas fun√ß√µes que voc√™ chamar**
3. **Se a fun√ß√£o retornar vazio, diga que n√£o h√° dados dispon√≠veis**
4. **NUNCA mencione subesta√ß√µes que n√£o estejam no resultado da consulta**
5. **Toda estat√≠stica DEVE vir de uma fun√ß√£o chamada**

O QUE VOC√ä PODE RESPONDER:
‚úÖ Perguntas sobre subesta√ß√µes (qual gera mais, qual consome mais, etc)
‚úÖ Estat√≠sticas do sistema (quantos consumidores, total de GD, etc)
‚úÖ An√°lise de risco (quais subesta√ß√µes em risco cr√≠tico)
‚úÖ Distribui√ß√£o de consumo por classe (residencial, comercial, industrial)
‚úÖ Detalhes espec√≠ficos de uma subesta√ß√£o

O QUE VOC√ä N√ÉO DEVE RESPONDER:
‚ùå Como o sistema funciona tecnicamente
‚ùå Como foi desenvolvido
‚ùå Explica√ß√µes sobre agentes de IA
‚ùå Arquitetura do sistema
‚ùå C√≥digo-fonte ou implementa√ß√£o

IMPORTANTE:
- SEMPRE responda em PORTUGU√äS do Brasil
- Use n√∫meros formatados (ex: 45.234,5 MWh)
- Seja objetivo e direto
- Se n√£o tiver dados, diga claramente "N√£o h√° dados dispon√≠veis"
- Quando consultar o banco, cite APENAS os n√∫meros retornados pela fun√ß√£o
- **PROIBIDO inventar nomes ou valores que n√£o vieram das fun√ß√µes**
"""

tools = [
    types.Tool(
        function_declarations=[
            types.FunctionDeclaration(
                name="obter_ranking_subestacoes",
                description="Retorna ranking de subesta√ß√µes ordenado por consumo ou gera√ß√£o distribu√≠da",
                parameters={
                    "type": "object",
                    "properties": {
                        "criterio": {
                            "type": "string",
                            "enum": ["consumo", "geracao"],
                            "description": "Crit√©rio de ordena√ß√£o: 'consumo' (MWh/ano) ou 'geracao' (kW de GD)"
                        },
                        "ordem": {
                            "type": "string",
                            "enum": ["desc", "asc"],
                            "description": "Ordem: 'desc' (maior para menor) ou 'asc' (menor para maior)"
                        },
                        "limite": {
                            "type": "integer",
                            "description": "N√∫mero m√°ximo de resultados"
                        }
                    },
                    "required": ["criterio"]
                }
            ),
            types.FunctionDeclaration(
                name="obter_subestacoes_em_risco",
                description="Retorna subesta√ß√µes com alto n√≠vel de criticidade de gera√ß√£o distribu√≠da",
                parameters={
                    "type": "object",
                    "properties": {
                        "nivel_minimo": {
                            "type": "string",
                            "enum": ["BAIXO", "MEDIO", "ALTO"],
                            "description": "N√≠vel m√≠nimo de criticidade para filtrar"
                        }
                    },
                    "required": []
                }
            ),
            types.FunctionDeclaration(
                name="obter_estatisticas_gerais",
                description="Retorna estat√≠sticas gerais do sistema: totais de subesta√ß√µes, consumidores, unidades GD e pot√™ncia total",
                parameters={
                    "type": "object",
                    "properties": {}
                }
            ),
            types.FunctionDeclaration(
                name="buscar_subestacao_detalhes",
                description="Busca informa√ß√µes detalhadas de uma subesta√ß√£o espec√≠fica pelo nome",
                parameters={
                    "type": "object",
                    "properties": {
                        "nome": {
                            "type": "string",
                            "description": "Nome completo ou parcial da subesta√ß√£o"
                        }
                    },
                    "required": ["nome"]
                }
            ),
            types.FunctionDeclaration(
                name="obter_distribuicao_consumo_por_classe",
                description="Retorna distribui√ß√£o total de consumo por classe de consumidor (Residencial, Comercial, Industrial, Rural, Poder P√∫blico)",
                parameters={
                    "type": "object",
                    "properties": {}
                }
            )
        ]
    )
]

class ChatRequest(BaseModel):
    mensagem: str
    historico: List[Dict[str, str]] = []

class ChatResponse(BaseModel):
    resposta: str
    historico_atualizado: List[Dict[str, str]]

@app.post("/chat/message", response_model=ChatResponse)
def enviar_mensagem(request: ChatRequest):
    try:
        contents = [types.Content(role="user", parts=[types.Part(text=CONTEXTO_SISTEMA)])]
        
        for msg in request.historico:
            role = "user" if msg["role"] == "user" else "model"
            contents.append(types.Content(role=role, parts=[types.Part(text=msg["content"])]))
        
        contents.append(types.Content(role="user", parts=[types.Part(text=request.mensagem)]))
        
        try:
            response = client.models.generate_content(
                model='gemini-3-flash-preview',
                contents=contents,
                config=types.GenerateContentConfig(
                    tools=tools,
                    temperature=0.7
                )
            )
        except Exception as e:
            if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
                # Retornar resposta v√°lida com mensagem de erro
                return ChatResponse(
                    resposta="‚è∞ **Cota da API Gemini excedida!**\n\nO plano gratuito do modelo `gemini-3-flash-preview` permite apenas **20 requisi√ß√µes por dia**.\n\n**Solu√ß√µes:**\n1. Aguardar at√© amanh√£ (~3h AM) para renova√ß√£o da cota\n2. Criar nova API key em outro projeto do Google Cloud\n3. Fazer upgrade para plano pago\n\n[Gerenciar API Keys](https://aistudio.google.com/app/apikey)",
                    historico_atualizado=request.historico
                )
            raise
        
        historico_atual = list(request.historico)
        historico_atual.append({"role": "user", "content": request.mensagem})
        
        while response.candidates[0].content.parts[0].function_call:
            function_call = response.candidates[0].content.parts[0].function_call
            function_name = function_call.name
            function_args = dict(function_call.args)
            
            print(f"üîß Chamando fun√ß√£o: {function_name} com args: {function_args}")
            
            if function_name in FUNCOES_DISPONIVEIS:
                resultado = FUNCOES_DISPONIVEIS[function_name](**function_args)
            else:
                resultado = {"erro": f"Fun√ß√£o {function_name} n√£o encontrada"}
            
            contents.append(response.candidates[0].content)
            
            contents.append(types.Content(
                role="function",
                parts=[types.Part(
                    function_response=types.FunctionResponse(
                        name=function_name,
                        response={"result": resultado}
                    )
                )]
            ))
            
            try:
                response = client.models.generate_content(
                    model='gemini-3-flash-preview',
                    contents=contents,
                    config=types.GenerateContentConfig(tools=tools)
                )
            except Exception as e:
                error_str = str(e)
                if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                    return ChatResponse(
                        resposta="‚è∞ **Cota da API Gemini excedida durante processamento!**\n\nO sistema conseguiu consultar os dados, mas a cota acabou ao formatar a resposta.\n\n**Solu√ß√µes:**\n1. Aguardar at√© amanh√£ (~3h AM)\n2. Criar nova API key em outro projeto\n\nDados consultados: fun√ß√£o `" + function_name + "` executada com sucesso.",
                        historico_atualizado=historico_atual
                    )
                elif "503" in error_str or "UNAVAILABLE" in error_str or "overloaded" in error_str.lower():
                    return ChatResponse(
                        resposta="üîÑ **Servidor Gemini temporariamente indispon√≠vel**\n\nO servidor do Google Gemini est√° sobrecarregado neste momento.\n\n‚úÖ **Seus dados foram consultados com sucesso:**\n- Fun√ß√£o `" + function_name + "` executada\n\nüí° **Tente novamente em alguns segundos!**",
                        historico_atualizado=historico_atual
                    )
                raise
        
        
        
        # Debug completo do response
        print(f"üîç DEBUG - Tipo do response: {type(response)}")
        print(f"üîç DEBUG - Tem candidates? {hasattr(response, 'candidates') and len(response.candidates) > 0 if hasattr(response, 'candidates') else 'N√£o'}")
        
        if hasattr(response, 'candidates') and response.candidates:
            print(f"üîç DEBUG - N√∫mero de candidates: {len(response.candidates)}")
            if len(response.candidates) > 0:
                first_candidate = response.candidates[0]
                print(f"üîç DEBUG - Tem content? {hasattr(first_candidate, 'content')}")
                if hasattr(first_candidate, 'content') and first_candidate.content:
                    print(f"üîç DEBUG - N√∫mero de parts: {len(first_candidate.content.parts) if hasattr(first_candidate.content, 'parts') else 0}")
                    if hasattr(first_candidate.content, 'parts') and first_candidate.content.parts:
                        for idx, part in enumerate(first_candidate.content.parts):
                            print(f"üîç DEBUG - Part {idx}: {dir(part)[:5]}")  # Primeiros 5 atributos
        
        resposta_final = response.text
        
        # Debug: verificar se resposta est√° vazia
        print(f"üîç DEBUG - response.text: '{resposta_final[:100] if resposta_final else 'VAZIO'}'")
        
        # Fallback: tentar extrair de candidates se text estiver vazio
        if not resposta_final or resposta_final.strip() == "":
            print(f"‚ö†Ô∏è response.text vazio! Tentando extrair de candidates...")
            try:
                if hasattr(response, 'candidates') and response.candidates:
                    parts = response.candidates[0].content.parts
                    if parts and len(parts) > 0 and hasattr(parts[0], 'text'):
                        resposta_final = parts[0].text
                        print(f"‚úÖ Extra√≠do de candidates.parts: '{resposta_final[:100]}'")
            except Exception as ex:
                print(f"‚ùå Erro ao extrair: {ex}")
        
        # Se ainda vazio, mensagem de erro
        if not resposta_final or resposta_final.strip() == "":
            resposta_final = "‚ö†Ô∏è O modelo processou a requisi√ß√£o mas n√£o retornou texto. Os dados foram consultados com sucesso no banco."
        
        historico_atual.append({"role": "assistant", "content": resposta_final})
        
        return ChatResponse(
            resposta=resposta_final,
            historico_atualizado=historico_atual
        )
        
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Erro no chat: {str(e)}")

@app.get("/health")
def health_check():
    return {
        "status": "ok",
        "model": "gemini-3-flash-preview",
        "api_configured": CHAT_API_KEY is not None
    }

if __name__ == "__main__":
    print("\nüöÄ Iniciando GridScope Chat IA Service...")
    print(f"üì° Modelo: gemini-3-flash-preview (20 req/dia)")
    print(f"üîë API Key configurada: {'Sim' if CHAT_API_KEY else 'N√ÉO'}")
    print("\nüí° Acesse a documenta√ß√£o em: http://localhost:8002/docs\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8002)
